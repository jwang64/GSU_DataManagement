{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "from lxml import html\n",
    "import requests\n",
    "import unicodecsv as csv\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen as uReq\n",
    "from fake_useragent import UserAgent\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting transcript links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://seekingalpha.com/earnings/earnings-call-transcripts/\"\n",
    "\n",
    "page = 1\n",
    "link_store = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(page <= 10):\n",
    "    new_url = url + str(page)\n",
    "    page = page + 1\n",
    "    html_content = requests.get(new_url).text\n",
    "    \n",
    "    # Parse the html content\n",
    "    soup_link = soup(html_content, \"lxml\")\n",
    "\n",
    "    for link in soup_link.findAll('a',{\"class\":\"dashboard-article-link\"}):\n",
    "            link_href = link.get('href')\n",
    "            combined_link = 'https://seekingalpha.com' + link_href\n",
    "            link_store.append(combined_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlink_store.append(\"https://seekingalpha.com/article/4393745-newmont-corporation-nem-ceo-tom-palmer-hosts-2021-investor-update-call-transcript\")\\nlink_store.append(\"https://seekingalpha.com/article/4393736-mongodb-inc-mdb-ceo-dev-ittycheria-on-q3-2021-results-earnings-call-transcript\")\\nlink_store.append(\"https://seekingalpha.com/article/4393631-barnes-noble-education-inc-bned-ceo-mike-huseby-on-q2-2021-results-earnings-call-transcript\")\\nlink_store.append(\"https://seekingalpha.com/article/4393377-lightinthebox-holding-co-ltd-s-litb-ceo-jian-on-q3-2020-results-earnings-call-transcript\")\\nlink_store.append(\"https://seekingalpha.com/article/4392903-idt-corporations-idt-ceo-shmuel-jonas-on-q1-2021-results-earnings-call-transcript\")\\nlink_store.append(\"https://seekingalpha.com/article/4392859-union-pacific-corporation-unp-ceo-lance-fritz-presents-credit-suisse-8th-annual-virtual\")\\nlink_store.append(\"https://seekingalpha.com/article/4392655-sarepta-therapeutics-inc-srpt-presents-evercore-isi-healthconx-conference-transcript\")\\nlink_store.append(\"https://seekingalpha.com/article/4392571-regeneron-pharmaceuticals-incs-regn-management-presents-piper-sandler-32nd-annual-virtual\")\\nlink_store.append(\"https://seekingalpha.com/article/4392384-twitter-inc-twtr-presents-bofa-2020-leveraged-finance-virtual-conference-transcript\")\\nlink_store.append(\"https://seekingalpha.com/article/4391728-laix-inc-s-laix-ceo-yi-wang-on-q3-2020-results-earnings-call-transcript\")\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "link_store.append(\"https://seekingalpha.com/article/4393745-newmont-corporation-nem-ceo-tom-palmer-hosts-2021-investor-update-call-transcript\")\n",
    "link_store.append(\"https://seekingalpha.com/article/4393736-mongodb-inc-mdb-ceo-dev-ittycheria-on-q3-2021-results-earnings-call-transcript\")\n",
    "link_store.append(\"https://seekingalpha.com/article/4393631-barnes-noble-education-inc-bned-ceo-mike-huseby-on-q2-2021-results-earnings-call-transcript\")\n",
    "link_store.append(\"https://seekingalpha.com/article/4393377-lightinthebox-holding-co-ltd-s-litb-ceo-jian-on-q3-2020-results-earnings-call-transcript\")\n",
    "link_store.append(\"https://seekingalpha.com/article/4392903-idt-corporations-idt-ceo-shmuel-jonas-on-q1-2021-results-earnings-call-transcript\")\n",
    "link_store.append(\"https://seekingalpha.com/article/4392859-union-pacific-corporation-unp-ceo-lance-fritz-presents-credit-suisse-8th-annual-virtual\")\n",
    "link_store.append(\"https://seekingalpha.com/article/4392655-sarepta-therapeutics-inc-srpt-presents-evercore-isi-healthconx-conference-transcript\")\n",
    "link_store.append(\"https://seekingalpha.com/article/4392571-regeneron-pharmaceuticals-incs-regn-management-presents-piper-sandler-32nd-annual-virtual\")\n",
    "link_store.append(\"https://seekingalpha.com/article/4392384-twitter-inc-twtr-presents-bofa-2020-leveraged-finance-virtual-conference-transcript\")\n",
    "link_store.append(\"https://seekingalpha.com/article/4391728-laix-inc-s-laix-ceo-yi-wang-on-q3-2020-results-earnings-call-transcript\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Collection Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTitle(transcript_soup):\n",
    "    title = str(transcript_soup.findAll(\"title\")[0])\n",
    "    title = title.replace('<title>','')\n",
    "    title = title.replace('</title>','')\n",
    "    return title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTicker(title):\n",
    "    ticker = re.findall(r'\\((.*?)\\)',title)[0]\n",
    "    return ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCompany(title):\n",
    "    company = re.findall(r'^([^.]*).*',title)[0]\n",
    "    return company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDate(transcript_soup):\n",
    "    date = str(transcript_soup.findAll('meta',{'name':'last-modified'})[0])\n",
    "    date =date.replace('<meta content=\"','')\n",
    "    date = date.split(' ')[0]\n",
    "    return date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Call Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_converter(time_string):\n",
    "    if('PM' in time_string):\n",
    "        number, remaining = time_string.split(':')\n",
    "        remaining = remaining.replace(' PM','')\n",
    "        changed_number = str(int(number) + 12)\n",
    "        return (changed_number + ':' + remaining)\n",
    "    else:\n",
    "        time_string = time_string.replace(' AM','')\n",
    "        return time_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTime(transcript_soup):\n",
    "    time_description = str(transcript_soup.findAll('meta',{'name':'description'}))\n",
    "    time = (re.search(r'\\d?\\d:\\d\\d[\\s]\\w[.]?\\w', time_description))[0]\n",
    "    time = time_converter(time)\n",
    "    return time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Presentation Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPresentationSpeech(transcript_soup):\n",
    "    overall_text = transcript_soup.findAll('p')\n",
    "    split_text = str(overall_text).split('question-answer-session')\n",
    "    presentation_speech = split_text[0]\n",
    "    return presentation_speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question Answer Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQuestionAnswerSpeech(transcript_soup):\n",
    "    overall_text = transcript_soup.findAll('p')\n",
    "    split_text = str(overall_text).split('question-answer-session')\n",
    "    question_answer_speech = split_text[1]\n",
    "    return question_answer_speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Company Participant Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCompanyParticipants(transcript_soup):\n",
    "    merged_p = ''\n",
    "    for p in transcript_soup.findAll('p', {'class':'p p1'}):\n",
    "        merged_p = merged_p + ' ' + str(p)\n",
    "    company_split = merged_p.split('p1\"><strong>Conference')\n",
    "    company_participant_half = company_split[0]\n",
    "    company_participant_list = re.findall(r'\\S+ \\S+ -',company_participant_half)\n",
    "    participant_index = 0\n",
    "    for participant in company_participant_list:\n",
    "        participant = participant.replace('p1\">','')\n",
    "        company_participant_list[participant_index] = participant.replace(' -', '')\n",
    "        participant_index = participant_index + 1\n",
    "    company_participant_string = ''\n",
    "    for company_participant in company_participant_list:\n",
    "        if company_participant_string == \"\":\n",
    "            company_participant_string = company_participant\n",
    "        else:\n",
    "            company_participant_string = company_participant_string + '.+.' + company_participant\n",
    "    return company_participant_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Noncompany Participant Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNoncompanyParticipants(transcript_soup):\n",
    "    merged_p = ''\n",
    "    for p in transcript_soup.findAll('p', {'class':'p p1'}):\n",
    "        merged_p = merged_p + ' ' + str(p)\n",
    "    company_split = merged_p.split('p1\"><strong>Conference')\n",
    "    if(len(company_split) > 1):\n",
    "        other_participant_half = company_split[1]\n",
    "\n",
    "        other_participant_list = re.findall(r'\\S+ \\S+ -',other_participant_half)\n",
    "        participant_index_noncompany = 0\n",
    "        for participant in other_participant_list:\n",
    "            participant = participant.replace('p1\">','')\n",
    "            other_participant_list[participant_index_noncompany] = participant.replace(' -', '')\n",
    "            participant_index_noncompany = participant_index_noncompany + 1\n",
    "        noncompany_participant_string = ''\n",
    "        for noncompany_participant in other_participant_list:\n",
    "            if noncompany_participant_string == \"\":\n",
    "                noncompany_participant_string = noncompany_participant\n",
    "            else:\n",
    "                noncompany_participant_string = noncompany_participant_string + '.+.' + noncompany_participant\n",
    "        return noncompany_participant_string\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Company Participant Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCompanyParticipantType(transcript_soup):\n",
    "    merged_p = ''\n",
    "    for p in transcript_soup.findAll('p', {'class':'p p1'}):\n",
    "        merged_p = merged_p + ' ' + str(p)\n",
    "    company_split = merged_p.split('p1\"><strong>Conference')\n",
    "    company_participant_half = company_split[0]\n",
    "    title_list = re.findall(r'- \\S+[^<]*',company_participant_half)\n",
    "    title_index = 0\n",
    "    for title in title_list:\n",
    "        title = title.replace(',','')\n",
    "        title_list[title_index] = title.replace('- ', '')\n",
    "        title_index = title_index + 1\n",
    "    title_list_string = ''\n",
    "    for title in title_list:\n",
    "        title = title.replace(',','')\n",
    "        if title_list_string == \"\":\n",
    "            title_list_string = title\n",
    "        else:\n",
    "            title_list_string = title_list_string + '.+.' + title\n",
    "    return title_list_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Noncompany Participant Organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNoncompanyParticipantOrganizations(transcript_soup):\n",
    "    merged_p = ''\n",
    "    for p in transcript_soup.findAll('p', {'class':'p p1'}):\n",
    "        merged_p = merged_p + ' ' + str(p)\n",
    "    company_split = merged_p.split('p1\"><strong>Conference')\n",
    "    if(len(company_split)>1):\n",
    "        other_participant_half = company_split[1]\n",
    "\n",
    "        organization_list = re.findall(r'- \\S+[^<]*',other_participant_half)\n",
    "\n",
    "        title_index_organization = 0\n",
    "        for organization in organization_list:\n",
    "            organization_list[title_index_organization] = organization.replace('- ', '')\n",
    "            title_index_organization = title_index_organization + 1\n",
    "        participant_organization_string = ''\n",
    "\n",
    "        for organization in organization_list:\n",
    "            organization = organization.replace(',','')\n",
    "            if participant_organization_string == \"\":\n",
    "                participant_organization_string = organization\n",
    "            else:\n",
    "                participant_organization_string = participant_organization_string + '.+.' + organization\n",
    "        return participant_organization_string\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_scrape_column_list = ['ticker','company','title','date','call_time','presentation_speech','question_answer_speech','company_participant_list','noncompany_participant_list','company_participant_type','noncompany_participant_organization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_scrape = pd.DataFrame(columns=transcript_scrape_column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>call_time</th>\n",
       "      <th>presentation_speech</th>\n",
       "      <th>question_answer_speech</th>\n",
       "      <th>company_participant_list</th>\n",
       "      <th>noncompany_participant_list</th>\n",
       "      <th>company_participant_type</th>\n",
       "      <th>noncompany_participant_organization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ticker, company, title, date, call_time, presentation_speech, question_answer_speech, company_participant_list, noncompany_participant_list, company_participant_type, noncompany_participant_organization]\n",
       "Index: []"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_scrape.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "headers = {\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\", \n",
    "    \"Accept-Encoding\": \"gzip, deflate\", \n",
    "    \"Accept-Language\": \"en-GB,en-US;q=0.9,en;q=0.8\", \n",
    "    \"Dnt\": \"1\", \n",
    "    \"Host\": \"httpbin.org\", \n",
    "    \"Upgrade-Insecure-Requests\": \"1\", \n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\", \n",
    "  }\n",
    "'''\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "delays = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-7350fd4aa153>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#Pulling features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetTitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranscript_soup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mticker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetTicker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mcompany\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetCompany\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetDate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranscript_soup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-79f3b02f184a>\u001b[0m in \u001b[0;36mgetTicker\u001b[1;34m(title)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetTicker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mticker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\((.*?)\\)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mticker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for link in link_store:\n",
    "    #Getting the transcript\n",
    "    transcript_url = link\n",
    "    transcript_content = requests.get(transcript_url, headers = headers).text\n",
    "    transcript_soup = soup(transcript_content, \"lxml\")\n",
    "    \n",
    "    #Pulling features\n",
    "    title = getTitle(transcript_soup)\n",
    "    ticker = getTicker(title)\n",
    "    company = getCompany(title)\n",
    "    date = getDate(transcript_soup)\n",
    "    call_time = getTime(transcript_soup)\n",
    "    presentation_speech = getPresentationSpeech(transcript_soup)\n",
    "    question_answer_speech = getQuestionAnswerSpeech(transcript_soup)\n",
    "    company_participant_list = getCompanyParticipants(transcript_soup)\n",
    "    noncompany_participant_list = getNoncompanyParticipants(transcript_soup)\n",
    "    company_participant_type = getCompanyParticipantType(transcript_soup)\n",
    "    noncompany_participant_organization = getNoncompanyParticipantOrganizations(transcript_soup)\n",
    "    link_store.remove(link)\n",
    "    delay = np.random.choice(delays)\n",
    "    time.sleep(delay)\n",
    "    \n",
    "    #Storing into dataframe\n",
    "    company_transcript_data = [ticker, company, title, date, call_time, presentation_speech, question_answer_speech, company_participant_list, noncompany_participant_list, company_participant_type, noncompany_participant_organization]\n",
    "    transcript_scrape.loc[len(transcript_scrape)] = company_transcript_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>call_time</th>\n",
       "      <th>presentation_speech</th>\n",
       "      <th>question_answer_speech</th>\n",
       "      <th>company_participant_list</th>\n",
       "      <th>noncompany_participant_list</th>\n",
       "      <th>company_participant_type</th>\n",
       "      <th>noncompany_participant_organization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ticker, company, title, date, call_time, presentation_speech, question_answer_speech, company_participant_list, noncompany_participant_list, company_participant_type, noncompany_participant_organization]\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_scrape.to_excel(\"transcript_scrape_demo.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
